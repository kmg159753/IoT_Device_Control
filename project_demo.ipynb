{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "966d59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a46cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from model import model_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96726279",
   "metadata": {},
   "outputs": [],
   "source": [
    "facerec = dlib.face_recognition_model_v1('model_1113/dlib_face_recognition_resnet_model_v1.dat')\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "mp68=[143,116,123,147,192,210,211,208,199,428,431,430,416,376,352,345,372,\n",
    "70,63,105,66,107,\n",
    "336,296,334,293,300,\n",
    "168,197,5,4,75,97,2,326,305,\n",
    "33,160,158,133,153,144,362,385,387,263,373,\n",
    "380,61,39,37,0,267,269,291,405,314,17,84,181,78,82,13,312,308,317,14,87]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c56c4",
   "metadata": {},
   "source": [
    "# Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3187184",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def find_faces(image,results):\n",
    "    # Draw the face mesh annotations on the image.\n",
    "    rects=[]\n",
    "    shapes=dlib.full_object_detections()\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "# ------------------------------\n",
    "            skipface=False\n",
    "            points=dlib.points()\n",
    "            p=face_landmarks.landmark\n",
    "            ld68=[]\n",
    "            for i in mp68:\n",
    "                px=int(image.shape[1]*p[i].x)\n",
    "                py=int(image.shape[0]*p[i].y)\n",
    "                if px<0 or px>image.shape[1] or py<0 or py>image.shape[0]:\n",
    "                    skipface=True\n",
    "                    results.multi_face_landmarks.remove(face_landmarks)\n",
    "                    break\n",
    "                \n",
    "                ld68.append([px,py])\n",
    "                points.append(dlib.point(px,py))\n",
    "            \n",
    "            if skipface:\n",
    "                continue\n",
    "\n",
    "            cx=int((ld68[39][0]+ld68[42][0])/2)\n",
    "            cy=ld68[29][1]\n",
    "\n",
    "\n",
    "            x,y,w,h=cv2.boundingRect(np.array(ld68))\n",
    "            if w<h:\n",
    "                x-=int((h-w)/2)\n",
    "                w=h\n",
    "            elif w>h:\n",
    "                y-=int((w-h)/2)\n",
    "                h=w\n",
    "\n",
    "            rcx=int(x+(w/2))\n",
    "            rcy=int(y+(h/2))\n",
    "            x+=(cx-rcx)\n",
    "            y+=(cy-rcy)\n",
    "# ------------------------------\n",
    "    \n",
    "            rect=((x,y),(x+w,y+h))\n",
    "            rects.append(rect)\n",
    "            shape=dlib.full_object_detection(dlib.rectangle(x,y,x+w,y+h),points)\n",
    "            shapes.append(shape)\n",
    "    return rects,shapes,[]\n",
    "\n",
    "def rect_faces(image,results):\n",
    "    # Draw the face mesh annotations on the image.\n",
    "    rects=[]\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            \n",
    "            p=face_landmarks.landmark\n",
    "            ld68=[]\n",
    "            for i in mp68:\n",
    "                px=int(image.shape[1]*p[i].x)\n",
    "                py=int(image.shape[0]*p[i].y)\n",
    "                ld68.append([px,py])\n",
    "\n",
    "            cx=int((ld68[39][0]+ld68[42][0])/2)\n",
    "            cy=ld68[29][1]\n",
    "\n",
    "            x,y,w,h=cv2.boundingRect(np.array(ld68))\n",
    "            if w<h:\n",
    "                x-=int((h-w)/2)\n",
    "                w=h\n",
    "            elif w>h:\n",
    "                y-=int((w-h)/2)\n",
    "                h=w\n",
    "\n",
    "            rcx=int(x+(w/2))\n",
    "            rcy=int(y+(h/2))\n",
    "            x+=(cx-rcx)\n",
    "            y+=(cy-rcy)\n",
    "            \n",
    "            rect=((x,y),(x+w,y+h))\n",
    "            rects.append(rect)\n",
    "    return rects\n",
    "\n",
    "\n",
    "def encode_faces(img, shapes):\n",
    "    face_descriptors = facerec.compute_face_descriptor(img, shapes)\n",
    "\n",
    "    return np.array(face_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e54bc9fa",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def processFR(image,results,adminIndex):\n",
    "    # 얼굴 인식 후 사용자 face index 업데이트\n",
    "    # image - RGB\n",
    "    \n",
    "    rects, shapes, _ = find_faces(image,results)\n",
    "    descs = encode_faces(image, shapes)\n",
    "    admindiststemp={}\n",
    "\n",
    "    \n",
    "    for i, desc in enumerate(descs):\n",
    "    \n",
    "        found = False\n",
    "        names=[]\n",
    "        dists=[]\n",
    "        for name, admindesc in adminfacedescs.items():\n",
    "            dist = np.linalg.norm([desc] - admindesc, axis=1)\n",
    "            if dist < 0.5:\n",
    "                found = True\n",
    "                names.append(name)\n",
    "                dists.append(dist)\n",
    "\n",
    "        if found:\n",
    "            dists=np.array(dists)\n",
    "            idx=np.argmin(dists)\n",
    "            name=names[idx]\n",
    "            \n",
    "            if name in admindiststemp:\n",
    "                \n",
    "                if dists[idx]<admindiststemp[name][1]:\n",
    "                    admindiststemp[name]=[i,dists[idx]]\n",
    "            else:\n",
    "                admindiststemp[name]=[i,dists[idx]]\n",
    "            \n",
    "    # 중복 검출 필터링\n",
    "    for name, item in admindiststemp.items():\n",
    "        adminIndex[item[0]]=name\n",
    "        \n",
    "    return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae0d7128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T18:05:43.516858Z",
     "start_time": "2022-11-11T18:05:43.500250Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def processECD(image,rects,results,adminIndex):\n",
    "    global lastecd\n",
    "    global js\n",
    "    global activatedAdmin\n",
    "    global lastactivated\n",
    "    \n",
    "    face_imgs=None\n",
    "    face_order=[]\n",
    "    frame = Image.fromarray(image)\n",
    "    \n",
    "    if rects==-1:\n",
    "        rects=rect_faces(image,results)\n",
    "    if lastecd>=ecdterm:\n",
    "        # 응시 인식 진행\n",
    "        if activatedAdmin == '':\n",
    "            # 모든 사용자 응시 인식\n",
    "            for i,name in adminIndex.items():\n",
    "                l=rects[i][0][0]\n",
    "                t=rects[i][0][1]\n",
    "                r=rects[i][1][0]\n",
    "                b=rects[i][1][1]\n",
    "                # expand a bit\n",
    "                l -= (r-l)*0.2\n",
    "                r += (r-l)*0.2\n",
    "                t -= (b-t)*0.2\n",
    "                b += (b-t)*0.2\n",
    "                \n",
    "                face = frame.crop(([l,t,r,b]))\n",
    "                img = test_transforms(face)\n",
    "                img.unsqueeze_(0)\n",
    "                \n",
    "                if face_imgs is None:\n",
    "                    face_imgs=img\n",
    "                else:\n",
    "                    face_imgs = torch.cat([face_imgs, img])\n",
    "                \n",
    "                face_order.append(name)\n",
    "                \n",
    "        else:\n",
    "            # 특정 사용자 응시 인식\n",
    "            \n",
    "            for i,name in adminIndex.items():\n",
    "                if name==activatedAdmin:\n",
    "                    l=rects[i][0][0]\n",
    "                    t=rects[i][0][1]\n",
    "                    r=rects[i][1][0]\n",
    "                    b=rects[i][1][1]\n",
    "                    # expand a bit\n",
    "                    l -= (r-l)*0.2\n",
    "                    r += (r-l)*0.2\n",
    "                    t -= (b-t)*0.2\n",
    "                    b += (b-t)*0.2\n",
    "                    \n",
    "                    face = frame.crop(([l,t,r,b]))\n",
    "                    img = test_transforms(face)\n",
    "                    img.unsqueeze_(0)\n",
    "                    face_imgs=img\n",
    "                    \n",
    "                    face_order.append(name)\n",
    "                    break\n",
    "         \n",
    "        if face_imgs is not None:\n",
    "            # 모델 입력\n",
    "            output = model(face_imgs.cuda())\n",
    "            scores=torch.sigmoid(output)\n",
    "            idx=torch.argmax(output)\n",
    "            \n",
    "            # 최대값 인덱스\n",
    "            if activatedAdmin == '':\n",
    "                # 사용자 활성화\n",
    "                if scores[idx]>=0.85:\n",
    "                    activatedAdmin=face_order[idx]\n",
    "                    lastactivated=frametime\n",
    "                    js=1\n",
    "\n",
    "            else:\n",
    "                if scores[idx]<0.85:\n",
    "                    resetCheck()\n",
    "                else:\n",
    "                    lastactivated=frametime\n",
    "        lastecd=frametime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee9a7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T18:05:43.525692Z",
     "start_time": "2022-11-11T18:05:43.519788Z"
    }
   },
   "outputs": [],
   "source": [
    "def resetCheck():\n",
    "    global lastactivated\n",
    "    global activatedAdmin\n",
    "    global js\n",
    "    if frametime-lastactivated>=timeout:\n",
    "        activatedAdmin=''\n",
    "        js=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ff986e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab92fca",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# set up data transformation\n",
    "test_transforms = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# load model weights\n",
    "model_weight='data_1113/model_weights.pkl'\n",
    "model = model_static(model_weight)\n",
    "model_dict = model.state_dict()\n",
    "snapshot = torch.load(model_weight)\n",
    "model_dict.update(snapshot)\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "model.cuda()\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f783ae7",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "adminList=['kim']\n",
    "\n",
    "adminfacedescs = {}\n",
    "\n",
    "activatedAdmin=''\n",
    "\n",
    "adminsEcdHistory={}\n",
    "\n",
    "ecdBuffer={}\n",
    "\n",
    "# System State\n",
    "ss=0\n",
    "# 얼굴 인식 진행\n",
    "# 모든 관리자 응시 인식 진행\n",
    "# 응시 중인 사용자 여부\n",
    "\n",
    "lastactivated=0\n",
    "\n",
    "# Jesture State\n",
    "js=0\n",
    "\n",
    "# ECD state\n",
    "es=0\n",
    "\n",
    "# last ecd time\n",
    "lastecd=0\n",
    "\n",
    "ecdterm=0.3\n",
    "\n",
    "timeout=2.0\n",
    "\n",
    "# Previous People\n",
    "pp=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e9919fb",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# 사용자 얼굴 등록\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.6,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    img_bgr = cv2.imread('mingyu.jpg')\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(img_rgb)\n",
    "    rects, shapes, cords = find_faces(img_rgb,results)\n",
    "    adminfacedescs['kim']=encode_faces(img_rgb, shapes)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28676647",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c13a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T18:10:54.138988Z",
     "start_time": "2022-11-11T18:10:11.220536Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start Demo Program\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "pp=0\n",
    "frametime=time.time()\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=5,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.6,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        start = time.time()\n",
    "        \n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Empty camera frame.\")\n",
    "            break\n",
    "            \n",
    "        \n",
    "        framegap=time.time()-frametime\n",
    "        frametime=time.time()\n",
    "        img_h, img_w, img_c = image.shape\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image)\n",
    "        \n",
    "        if (results.multi_face_landmarks is None):\n",
    "            pp=0\n",
    "            adminIndex={}\n",
    "            # 활성화 사용자 리셋 체크\n",
    "            if activatedAdmin!='':\n",
    "                resetCheck()\n",
    "        \n",
    "        elif (pp != len(results.multi_face_landmarks)):\n",
    "            # 얼굴 인식 진행\n",
    "            adminIndex={}\n",
    "            rects=processFR(image,results,adminIndex)\n",
    "            pp=len(results.multi_face_landmarks)\n",
    "            \n",
    "            # 응시 인식 진행\n",
    "            processECD(image,rects,results,adminIndex)\n",
    "        else:\n",
    "            rects=-1\n",
    "            # 응시 인식 진행\n",
    "            processECD(image,rects,results,adminIndex)\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        # Draw the face mesh annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        faceIdx=0\n",
    "        if results.multi_face_landmarks:\n",
    "              for face_landmarks in results.multi_face_landmarks:\n",
    "                    mediapipe_lm=np.array([np.multiply([p.x,p.y],[img_w,img_h]).astype(int) for p in face_landmarks.landmark])\n",
    "                    if faceIdx in adminIndex:\n",
    "                        cv2.putText(image, f'{adminIndex[faceIdx]}', mediapipe_lm[152], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 20, 20), 2)\n",
    "                        \n",
    "                        \n",
    "                    faceIdx+=1\n",
    "        \n",
    "        end = time.time()\n",
    "        totalTime = end - start\n",
    "        \n",
    "        if activatedAdmin!='':\n",
    "            cv2.putText(image, f'{activatedAdmin}, Welcome.', (0,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 20, 20), 2)\n",
    "            \n",
    "        cv2.putText(image, f'{totalTime}', (0,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (25, 20, 20), 2)\n",
    "        \n",
    "        cv2.imshow('MediaPipe Face Mesh', image)\n",
    "        wk=cv2.waitKey(1)\n",
    "        if wk & 0xFF == 27: # esc\n",
    "            break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd22184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
